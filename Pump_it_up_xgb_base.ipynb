{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vNMHTa2cx7PcEIM3LxgHYpWHLKEyickY",
      "authorship_tag": "ABX9TyNgih6MsT/FfWqdyLcSjw3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellojohnkim/mmai894/blob/main/Pump_it_up_xgb_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specifying the datasets file paths\n",
        "training_set_values_file_path = '/content/drive/MyDrive/MMAI_Group/894_team/DrivenData_Competition/data/training_set_values.csv'\n",
        "training_set_labels_file_path = '/content/drive/MyDrive/MMAI_Group/894_team/DrivenData_Competition/data/training_set_label.csv'\n",
        "test_set_file_path = '/content/drive/MyDrive/MMAI_Group/894_team/DrivenData_Competition/data/test_set.csv'\n",
        "\n",
        "# Loading the datasets\n",
        "training_values = pd.read_csv(training_set_values_file_path)\n",
        "training_labels = pd.read_csv(training_set_labels_file_path)\n",
        "test_values = pd.read_csv(test_set_file_path)\n",
        "\n",
        "# Displaying the first few rows of the datasets\n",
        "training_values.head(), training_labels.head(), test_values.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcRkDDUjGcN6",
        "outputId": "7b96abfb-249c-42de-ff98-98927dcbdc2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
              " 0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n",
              " 1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n",
              " 2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n",
              " 3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n",
              " 4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n",
              " \n",
              "    longitude   latitude              wpt_name  num_private  ... payment_type  \\\n",
              " 0  34.938093  -9.856322                  none            0  ...     annually   \n",
              " 1  34.698766  -2.147466              Zahanati            0  ...    never pay   \n",
              " 2  37.460664  -3.821329           Kwa Mahundi            0  ...   per bucket   \n",
              " 3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...    never pay   \n",
              " 4  31.130847  -1.825359               Shuleni            0  ...    never pay   \n",
              " \n",
              "   water_quality quality_group      quantity  quantity_group  \\\n",
              " 0          soft          good        enough          enough   \n",
              " 1          soft          good  insufficient    insufficient   \n",
              " 2          soft          good        enough          enough   \n",
              " 3          soft          good           dry             dry   \n",
              " 4          soft          good      seasonal        seasonal   \n",
              " \n",
              "                  source           source_type  source_class  \\\n",
              " 0                spring                spring   groundwater   \n",
              " 1  rainwater harvesting  rainwater harvesting       surface   \n",
              " 2                   dam                   dam       surface   \n",
              " 3           machine dbh              borehole   groundwater   \n",
              " 4  rainwater harvesting  rainwater harvesting       surface   \n",
              " \n",
              "                waterpoint_type waterpoint_type_group  \n",
              " 0           communal standpipe    communal standpipe  \n",
              " 1           communal standpipe    communal standpipe  \n",
              " 2  communal standpipe multiple    communal standpipe  \n",
              " 3  communal standpipe multiple    communal standpipe  \n",
              " 4           communal standpipe    communal standpipe  \n",
              " \n",
              " [5 rows x 40 columns],\n",
              "       id    status_group\n",
              " 0  69572      functional\n",
              " 1   8776      functional\n",
              " 2  34310      functional\n",
              " 3  67743  non functional\n",
              " 4  19728      functional,\n",
              "       id  amount_tsh date_recorded                  funder  gps_height  \\\n",
              " 0  50785         0.0    2013-02-04                    Dmdd        1996   \n",
              " 1  51630         0.0    2013-02-04  Government Of Tanzania        1569   \n",
              " 2  17168         0.0    2013-02-01                     NaN        1567   \n",
              " 3  45559         0.0    2013-01-22              Finn Water         267   \n",
              " 4  49871       500.0    2013-03-27                  Bruder        1260   \n",
              " \n",
              "     installer  longitude   latitude                 wpt_name  num_private  \\\n",
              " 0        DMDD  35.290799  -4.059696  Dinamu Secondary School            0   \n",
              " 1         DWE  36.656709  -3.309214                  Kimnyak            0   \n",
              " 2         NaN  34.767863  -5.004344           Puma Secondary            0   \n",
              " 3  FINN WATER  38.058046  -9.418672           Kwa Mzee Pange            0   \n",
              " 4      BRUDER  35.006123 -10.950412          Kwa Mzee Turuka            0   \n",
              " \n",
              "    ... payment_type water_quality quality_group      quantity  quantity_group  \\\n",
              " 0  ...    never pay          soft          good      seasonal        seasonal   \n",
              " 1  ...    never pay          soft          good  insufficient    insufficient   \n",
              " 2  ...    never pay          soft          good  insufficient    insufficient   \n",
              " 3  ...      unknown          soft          good           dry             dry   \n",
              " 4  ...      monthly          soft          good        enough          enough   \n",
              " \n",
              "                  source           source_type  source_class  \\\n",
              " 0  rainwater harvesting  rainwater harvesting       surface   \n",
              " 1                spring                spring   groundwater   \n",
              " 2  rainwater harvesting  rainwater harvesting       surface   \n",
              " 3          shallow well          shallow well   groundwater   \n",
              " 4                spring                spring   groundwater   \n",
              " \n",
              "       waterpoint_type waterpoint_type_group  \n",
              " 0               other                 other  \n",
              " 1  communal standpipe    communal standpipe  \n",
              " 2               other                 other  \n",
              " 3               other                 other  \n",
              " 4  communal standpipe    communal standpipe  \n",
              " \n",
              " [5 rows x 40 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import numpy as np\n",
        "\n",
        "# One-Hot Encoding of Labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_labels = encoder.fit_transform(training_labels[['status_group']])\n",
        "\n",
        "# Encoding DateTime Variables\n",
        "training_values['date_recorded'] = pd.to_datetime(training_values['date_recorded'])\n",
        "test_values['date_recorded'] = pd.to_datetime(test_values['date_recorded'])\n",
        "training_values['year_recorded'] = training_values['date_recorded'].dt.year\n",
        "training_values['month_recorded'] = training_values['date_recorded'].dt.month\n",
        "training_values['day_recorded'] = training_values['date_recorded'].dt.day\n",
        "test_values['year_recorded'] = test_values['date_recorded'].dt.year\n",
        "test_values['month_recorded'] = test_values['date_recorded'].dt.month\n",
        "test_values['day_recorded'] = test_values['date_recorded'].dt.day\n",
        "training_values.drop('date_recorded', axis=1, inplace=True)\n",
        "test_values.drop('date_recorded', axis=1, inplace=True)\n",
        "\n",
        "# Columns to Drop\n",
        "columns_to_drop = ['funder', 'installer', 'scheme_name']\n",
        "training_values.drop(columns=columns_to_drop, inplace=True)\n",
        "test_values.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Simple Imputation for 'scheme_management'\n",
        "imputer_scheme_management = SimpleImputer(strategy='most_frequent')\n",
        "training_values['scheme_management'] = imputer_scheme_management.fit_transform(training_values[['scheme_management']])\n",
        "test_values['scheme_management'] = imputer_scheme_management.transform(test_values[['scheme_management']])\n",
        "\n",
        "# Label Encoding for categorical variables\n",
        "categorical_columns = training_values.select_dtypes(include=['object']).columns.tolist()\n",
        "label_encoders = {col: LabelEncoder() for col in categorical_columns if len(training_values[col].unique()) <= 50}\n",
        "\n",
        "# Adjusting Label Encoding to handle unseen categories in test data\n",
        "for col in categorical_columns:\n",
        "    if training_values[col].dtype == 'object':\n",
        "        # Combining the categories from both training and test sets\n",
        "        combined_categories = pd.concat([training_values[col], test_values[col]], axis=0).astype(str).unique()\n",
        "\n",
        "        # Creating a LabelEncoder with the combined categories\n",
        "        le = LabelEncoder().fit(combined_categories)\n",
        "\n",
        "        # Transforming both training and test sets\n",
        "        training_values[col] = le.transform(training_values[col].astype(str))\n",
        "        test_values[col] = le.transform(test_values[col].astype(str))\n",
        "\n",
        "# Reapplying MinMaxScaler to numeric features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns)\n",
        "    ],\n",
        "    remainder='passthrough'  # Keep other columns unchanged\n",
        ")\n",
        "\n",
        "# Transforming the datasets again after re-encoding\n",
        "X_train_processed = preprocessor.fit_transform(training_values)\n",
        "X_test_processed = preprocessor.transform(test_values)\n",
        "\n",
        "# Splitting the re-processed data into training and validation sets\n",
        "X_train, X_val, y_train_labels, y_val_labels = train_test_split(X_train_processed, np.argmax(encoded_labels, axis=1), test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofFaIrYkIy1x",
        "outputId": "027970bb-52b0-49d4-e6bc-1c181dfb6026"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.797053872053872,\n",
              " '              precision    recall  f1-score   support\\n\\n           0       0.78      0.91      0.84      6457\\n           1       0.60      0.25      0.35       851\\n           2       0.84      0.74      0.79      4572\\n\\n    accuracy                           0.80     11880\\n   macro avg       0.74      0.63      0.66     11880\\nweighted avg       0.79      0.80      0.79     11880\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Creating a baseline XGBoost model\n",
        "xgb_baseline = XGBClassifier(random_state=42)\n",
        "\n",
        "# Retraining the XGBoost model with the re-processed data\n",
        "xgb_baseline.fit(X_train, y_train_labels)\n",
        "\n",
        "# Making predictions on the validation set\n",
        "y_val_pred = xgb_baseline.predict(X_val)\n",
        "\n",
        "# Recalculating baseline performance\n",
        "accuracy_val = accuracy_score(y_val_labels, y_val_pred)\n",
        "classification_rep_val = classification_report(y_val_labels, y_val_pred, output_dict=True)\n",
        "\n",
        "# Performance metrics\n",
        "accuracy_val\n",
        "\n",
        "# Convert the classification report to a DataFrame\n",
        "classification_report_df = pd.DataFrame(classification_rep_val).transpose()\n",
        "\n",
        "# Display the classficiation report and accuracy\n",
        "print(classification_report_df)\n",
        "print(accuracy_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypJt0qYOKiJl",
        "outputId": "c5dc5e05-413e-4ac5-fde8-c8feb6431aa6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score       support\n",
            "0              0.781654  0.909246  0.840636   6457.000000\n",
            "1              0.602817  0.251469  0.354892    851.000000\n",
            "2              0.843049  0.740157  0.788260   4572.000000\n",
            "accuracy       0.797054  0.797054  0.797054      0.797054\n",
            "macro avg      0.742507  0.633624  0.661263  11880.000000\n",
            "weighted avg   0.792471  0.797054  0.785684  11880.000000\n",
            "0.797053872053872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweaking hyperparameters of the XGBoost model\n",
        "xgb_tweaked = XGBClassifier(\n",
        "    n_estimators=1000,  # Increasing the number of trees\n",
        "    learning_rate=0.1,  # Adjusting learning rate\n",
        "    max_depth=8,  # Setting a maximum depth for trees\n",
        "    subsample=0.8,  # Using 80% of data for fitting individual trees\n",
        "    colsample_bytree=0.8,  # Using 80% of features for constructing each tree\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Retraining the model with tweaked hyperparameters\n",
        "xgb_tweaked.fit(X_train, y_train_labels)\n",
        "\n",
        "# Making predictions on the validation set with the tweaked model\n",
        "y_val_pred_tweaked = xgb_tweaked.predict(X_val)\n",
        "\n",
        "# Recalculating performance with the tweaked model\n",
        "accuracy_val_tweaked = accuracy_score(y_val_labels, y_val_pred_tweaked)\n",
        "classification_rep_val_tweaked = classification_report(y_val_labels, y_val_pred_tweaked, output_dict=True)\n",
        "\n",
        "# Convert the classification report to a DataFrame\n",
        "classification_report_df = pd.DataFrame(classification_rep_val_tweaked).transpose()\n",
        "\n",
        "# Display the classification report and accuracy\n",
        "print(classification_report_df)\n",
        "print(accuracy_val_tweaked)\n"
      ],
      "metadata": {
        "id": "LHBn-PwRLift"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}